---
title: "Three Parameter IRT Models"
author: "Russell Almond"
date: "10/5/2021"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(arm)
```

## Three parameter Logistic

$$ p(X|\theta_i,a_j, b_j, c_j) = c_j + (1-c_j)\text{logit}^{-1} \left ( 1.7 a_j(\theta_i - b_j) \right ) \qquad \theta_i \sim N(0,1) $$

The parameter $c_j$ is called the guessing parameter.

This is intended for use with multiple choice questions, were $c_j$ is one over the number of options.  This becomes the _lower asymptote_ for the logistic curve.




```{shinylive-r}
#| standalone: true
#| viewerHeight: 1000
library(shiny)
library(arm)
ui <- fluidPage(
inputPanel(
  sliderInput("difficulty3", label = "Difficulty",
              min=-3.0, max=3.0, value=0, step=.1),
  
  sliderInput("discrimination3", label = "Discrimination:",
              min = 0.05, max = 2, value = 1, step = 0.05),
  sliderInput("guessing3",label="Guessing", min=0, max=.5, value=.25, step=.01),
sliderInput("master3", label = "Mastery Point",
              min=-3.0, max=3.0, value=0, step=.1)  
),
  mainPanel(plotOutput("ICC"),
            plotOutput("Info")))
server <- function (input,output) {

irt3pl <- function (x,a=1,b=0,c=.2,D=1.7) {
  c + (1-c)*invlogit(D*a*(x-b))
 }

info <- function (x,a,b,c,D=1.7) {
  p <- irt3pl(x,a,b,c,D)
  a^2*D^2*(p-c)^2/(1-c)^2*(1-p)/p
}

output$ICC <- renderPlot({
   b <- as.numeric(input$difficulty3)
   a <- as.numeric(input$discrimination3)
   c <- as.numeric(input$guessing3)
   curve(irt3pl(x,a,b,c),xlim=c(-3.25,3.25),
   ylab="Probability of Success", xlab="Ability",
   main=paste("IRT Curve; difficulty = ",b,
              ", discrimination =", a,
              ", guessing=", c),
   ylim=c(0,1))
 abline(v=input$master3)
 abline(h=c,lty="dotted")
})
   output$Info <- renderPlot({
   b <- as.numeric(input$difficulty3)
   a <- as.numeric(input$discrimination3)
   c <- as.numeric(input$guessing3)
   curve(info(x,a,b,c),xlim=c(-3.25,3.25),
	main="Item Information")
   abline(v=input$master3) 
   })
}
shinyApp(ui=ui,server=server)
```

The item information function is 

$$I(\theta) = a_j^2 D^2 \frac{p(\theta)-c_j)^2 q(\theta)}{(1-c_j)^2p(\theta)} \ , $$

where $p(\theta)=P(X=1|\theta,b_j)$ and $q(\theta)=1-p(\theta)$ and
$D$ is 1.7 or 1, $a_j$ is
the discrimination parameter, and $c_j$ is the guessing parameter.

3PL models are less stable than 1PL or 2PL models.  This has two consequences.  First, fitting 3PL models needs much larger sample sizes.  Second, it often helps to put a prior distribution (around one over the number of options) to help stabilizes the estimates.

Note that the MIRT package has an alternative 3PL model where the extra parameters is an upper asymptote, although I have not seen that used.
